# OpenAI

This page covers all LangChain integrations with [OpenAI](https://en.wikipedia.org/wiki/OpenAI)

## Model interfaces

<Columns cols={2}>
  <Card title="ChatOpenAI" href="/oss/python/integrations/chat/openai" cta="Get started" icon="message" arrow>
    OpenAI chat models.
  </Card>

  <Card title="AzureChatOpenAI" href="/oss/python/integrations/chat/azure_chat_openai" cta="Get started" icon="microsoft" arrow>
    Wrapper for OpenAI chat models hosted on Azure.
  </Card>

  <Card title="OpenAI" href="/oss/python/integrations/llms/openai" cta="Get started" icon="i-cursor" arrow>
    (Legacy) OpenAI text completion models.
  </Card>

  <Card title="AzureOpenAI" href="/oss/python/integrations/llms/azure_openai" cta="Get started" icon="microsoft" arrow>
    Wrapper for (legacy) OpenAI text completion models hosted on Azure.
  </Card>

  <Card title="OpenAIEmbeddings" href="/oss/python/integrations/text_embedding/openai" cta="Get started" icon="layer-group" arrow>
    OpenAI embedding models.
  </Card>

  <Card title="AzureOpenAIEmbeddings" href="/oss/python/integrations/text_embedding/azure_openai" cta="Get started" icon="microsoft" arrow>
    Wrapper for OpenAI embedding models hosted on Azure.
  </Card>
</Columns>

## Tools and toolkits

<Columns cols={2}>
  <Card title="Dall-E Image Generator" href="/oss/python/integrations/tools/dalle_image_generator" cta="Get started" icon="image" arrow>
    Text-to-image generation using OpenAI's Dall-E models.
  </Card>
</Columns>

## Retrievers

<Columns cols={2}>
  <Card title="ChatGPTPluginRetriever" href="/oss/python/integrations/retrievers/chatgpt-plugin" cta="Get started" icon="download" arrow>
    Retrieve real-time information; e.g., sports scores, stock prices, the latest news, etc.
  </Card>
</Columns>

## Document loaders

<Columns cols={2}>
  <Card title="ChatGPTLoader" href="/oss/python/integrations/document_loaders/chatgpt_loader" cta="Get started" icon="file" arrow>
    Load `conversations.json` from your ChatGPT data export folder.
  </Card>
</Columns>

## Middleware

Middleware specifically designed for OpenAI models. Learn more about [middleware](/oss/python/langchain/middleware/overview).

| Middleware                                | Description                                               |
| ----------------------------------------- | --------------------------------------------------------- |
| [Content moderation](#content-moderation) | Moderate agent traffic using OpenAI's moderation endpoint |

### Content moderation

Moderate agent traffic (user input, model output, and tool results) using OpenAI's moderation endpoint to detect and handle unsafe content. Content moderation is useful for the following:

* Applications requiring content safety and compliance
* Filtering harmful, hateful, or inappropriate content
* Customer-facing agents that need safety guardrails
* Meeting platform moderation requirements

<Info>
  Learn more about [OpenAI's moderation models](https://platform.openai.com/docs/guides/moderation) and categories.
</Info>

**API reference:** [`OpenAIModerationMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.OpenAIModerationMiddleware)

```python  theme={null}
from langchain_openai import ChatOpenAI
from langchain_openai.middleware import OpenAIModerationMiddleware
from langchain.agents import create_agent

agent = create_agent(
    model=ChatOpenAI(model="gpt-4o"),
    tools=[search_tool, database_tool],
    middleware=[
        OpenAIModerationMiddleware(
            model="omni-moderation-latest",
            check_input=True,
            check_output=True,
            exit_behavior="end",
        ),
    ],
)
```

<Accordion title="Configuration options">
  <ParamField body="model" type="ModerationModel" default="omni-moderation-latest">
    OpenAI moderation model to use. Options: `'omni-moderation-latest'`, `'omni-moderation-2024-09-26'`, `'text-moderation-latest'`, `'text-moderation-stable'`
  </ParamField>

  <ParamField body="check_input" type="bool" default="True">
    Whether to check user input messages before the model is called
  </ParamField>

  <ParamField body="check_output" type="bool" default="True">
    Whether to check model output messages after the model is called
  </ParamField>

  <ParamField body="check_tool_results" type="bool" default="False">
    Whether to check tool result messages before the model is called
  </ParamField>

  <ParamField body="exit_behavior" type="string" default="end">
    How to handle violations when content is flagged. Options:

    * `'end'` - End agent execution immediately with a violation message
    * `'error'` - Raise `OpenAIModerationError` exception
    * `'replace'` - Replace the flagged content with the violation message and continue
  </ParamField>

  <ParamField body="violation_message" type="str | None">
    Custom template for violation messages. Supports template variables:

    * `{categories}` - Comma-separated list of flagged categories
    * `{category_scores}` - JSON string of category scores
    * `{original_content}` - The original flagged content

    Default: `"I'm sorry, but I can't comply with that request. It was flagged for {categories}."`
  </ParamField>

  <ParamField body="client" type="OpenAI | None">
    Optional pre-configured OpenAI client to reuse. If not provided, a new client will be created.
  </ParamField>

  <ParamField body="async_client" type="AsyncOpenAI | None">
    Optional pre-configured AsyncOpenAI client to reuse. If not provided, a new async client will be created.
  </ParamField>
</Accordion>

<Accordion title="Full example">
  The middleware integrates OpenAI's moderation endpoint to check content at different stages:

  **Moderation stages:**

  * `check_input` - User messages before model call
  * `check_output` - AI messages after model call
  * `check_tool_results` - Tool outputs before model call

  **Exit behaviors:**

  * `'end'` (default) - Stop execution with violation message
  * `'error'` - Raise exception for application handling
  * `'replace'` - Replace flagged content and continue

  ```python  theme={null}
  from langchain_openai import ChatOpenAI
  from langchain_openai.middleware import OpenAIModerationMiddleware
  from langchain.agents import create_agent


  # Basic moderation
  agent = create_agent(
      model=ChatOpenAI(model="gpt-4o"),
      tools=[search_tool, customer_data_tool],
      middleware=[
          OpenAIModerationMiddleware(
              model="omni-moderation-latest",
              check_input=True,
              check_output=True,
          ),
      ],
  )

  # Strict moderation with custom message
  agent_strict = create_agent(
      model=ChatOpenAI(model="gpt-4o"),
      tools=[search_tool, customer_data_tool],
      middleware=[
          OpenAIModerationMiddleware(
              model="omni-moderation-latest",
              check_input=True,
              check_output=True,
              check_tool_results=True,
              exit_behavior="error",
              violation_message=(
                  "Content policy violation detected: {categories}. "
                  "Please rephrase your request."
              ),
          ),
      ],
  )

  # Moderation with replacement behavior
  agent_replace = create_agent(
      model=ChatOpenAI(model="gpt-4o"),
      tools=[search_tool],
      middleware=[
          OpenAIModerationMiddleware(
              check_input=True,
              exit_behavior="replace",
              violation_message="[Content removed due to safety policies]",
          ),
      ],
  )
  ```
</Accordion>

## Other

<Columns cols={2}>
  <Card title="Adapter" href="/oss/python/integrations/adapters/openai" cta="Get started" icon="arrows-left-right" arrow>
    Adapt LangChain models to OpenAI APIs.
  </Card>

  <Card title="OpenAIModerationChain" href="https://python.langchain.com/v0.1/docs/guides/productionization/safety/moderation" cta="Get started" icon="link" arrow>
    Detect text that could be hateful, violent, etc.
  </Card>
</Columns>

***

<Callout icon="pen-to-square" iconType="regular">
  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/openai.mdx)
</Callout>

<Tip icon="terminal" iconType="regular">
  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.langchain.com/llms.txt