# FalkorDBVectorStore

<a href="https://docs.falkordb.com/" target="_blank">FalkorDB</a> is an open-source graph database with integrated support for vector similarity search

it supports:

* approximate nearest neighbor search
* Euclidean similarity & Cosine Similarity
* Hybrid search combining vector and keyword searches

This notebook shows how to use the FalkorDB vector index (`FalkorDB`)

See the <a href="https://docs.falkordb.com/" target="_blank">installation instruction</a>

## Setup

```python  theme={null}
# Pip install necessary package
pip install -U  falkordb
pip install -U  tiktoken
pip install -U  langchain langchain_huggingface
```

### Credentials

We want to use `HuggingFace` so we have to get the HuggingFace API Key

```python  theme={null}
import getpass
import os

if "HUGGINGFACE_API_KEY" not in os.environ:
    os.environ["HUGGINGFACE_API_KEY"] = getpass.getpass("HuggingFace API Key:")
```

If you want to get automated tracing of your model calls you can also set your LangSmith API key by uncommenting below:

```python  theme={null}
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
os.environ["LANGSMITH_TRACING"] = "true"
```

## Initialization

```python  theme={null}
from langchain_community.vectorstores.falkordb_vector import FalkorDBVector
from langchain_core.documents import Document
from langchain_huggingface import HuggingFaceEmbeddings
```

You can use FalkorDBVector locally with docker. See <a href="https://docs.falkordb.com/" target="_blank">installation instruction</a>

```python  theme={null}
host = "localhost"
port = 6379
```

Or you can use FalkorDBVector with <a href="https://app.falkordb.cloud">FalkorDB Cloud</a>

```python  theme={null}
# E.g
# host = "r-6jissuruar.instance-zwb082gpf.hc-v8noonp0c.europe-west1.gcp.f2e0a955bb84.cloud"
# port = 62471
# username = "falkordb" # SET ON FALKORDB CLOUD
# password = "password" # SET ON FALKORDB CLOUD
```

```python  theme={null}
vector_store = FalkorDBVector(host=host, port=port, embedding=HuggingFaceEmbeddings())
```

## Manage vector store

### Add items to vector store

```python  theme={null}
from langchain_core.documents import Document

document_1 = Document(page_content="foo", metadata={"source": "https://example.com"})

document_2 = Document(page_content="bar", metadata={"source": "https://example.com"})

document_3 = Document(page_content="baz", metadata={"source": "https://example.com"})

documents = [document_1, document_2, document_3]

vector_store.add_documents(documents=documents, ids=["1", "2", "3"])
```

```output  theme={null}
['1', '2', '3']
```

### Update items in vector store

```python  theme={null}
updated_document = Document(
    page_content="qux", metadata={"source": "https://another-example.com"}
)

vector_store.update_documents(document_id="1", document=updated_document)
```

### Delete items from vector store

```python  theme={null}
vector_store.delete(ids=["3"])
```

## Query vector store

Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent.

### Query directly

Performing a simple similarity search can be done as follows:

```python  theme={null}
results = vector_store.similarity_search(
    query="thud", k=1, filter={"source": "https://another-example.com"}
)
for doc in results:
    print(f"* {doc.page_content} [{doc.metadata}]")
```

```output  theme={null}
* qux [{'text': 'qux', 'id': '1', 'source': 'https://another-example.com'}]
```

If you want to execute a similarity search and receive the corresponding scores you can run:

```python  theme={null}
results = vector_store.similarity_search_with_score(query="bar")
for doc, score in results:
    print(f"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]")
```

```output  theme={null}
* [SIM=0.000001] bar [{'text': 'bar', 'id': '2', 'source': 'https://example.com'}]
```

### Query by turning into retriever

You can also transform the vector store into a retriever for easier usage in your chains.

```python  theme={null}
retriever = vector_store.as_retriever(search_type="mmr", search_kwargs={"k": 1})
retriever.invoke("thud")
```

```output  theme={null}
[Document(metadata={'text': 'qux', 'id': '1', 'source': 'https://another-example.com'}, page_content='qux')]
```

***

## API reference

For detailed documentation of all `FalkorDBVector` features and configurations head to the API reference: [python.langchain.com/api\_reference/community/vectorstores/langchain\_community.vectorstores.falkordb\_vector.FalkorDBVector.html](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.falkordb_vector.FalkorDBVector.html)

***

<Callout icon="pen-to-square" iconType="regular">
  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/vectorstores/falkordbvector.mdx)
</Callout>

<Tip icon="terminal" iconType="regular">
  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.langchain.com/llms.txt