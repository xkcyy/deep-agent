#!/usr/bin/env python3
"""
ä»£ç åˆ†ææµ‹è¯• - éªŒè¯å…³é”®é€»è¾‘å’Œè¾¹ç•Œæƒ…å†µ
"""

import os
import sys
import tempfile
import shutil
from website_cloner_fixed import DownloadConfig, WebsiteCloner

def test_url_processing_edge_cases():
    """æµ‹è¯•URLå¤„ç†çš„è¾¹ç•Œæƒ…å†µ"""
    print("ğŸ§ª æµ‹è¯•URLå¤„ç†è¾¹ç•Œæƒ…å†µ...")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp(prefix="cloner_edge_test_")
    
    try:
        config = DownloadConfig(
            base_url="https://example.com",
            output_dir=temp_dir,
            max_depth=1,
            max_threads=1
        )
        
        cloner = WebsiteCloner(config)
        
        # æµ‹è¯•å„ç§è¾¹ç•ŒURL
        test_cases = [
            ("https://example.com/", "index.html"),
            ("https://example.com/path", "path/index.html"),
            ("https://example.com/file.html", "file.html"),
            ("https://example.com/dir/", "dir/index.html"),
            ("https://example.com/path/to/file.js", "path/to/file.js"),
            ("https://example.com/path%20with%20spaces.html", "path with spaces.html"),
        ]
        
        for url, expected_file in test_cases:
            local_path = cloner._get_local_path(url)
            relative_path = os.path.relpath(local_path, temp_dir)
            
            print(f"   {url}")
            print(f"   -> {relative_path}")
            print(f"   æœŸæœ›åŒ…å«: {expected_file}")
            
            if expected_file in relative_path:
                print("   âœ… æ­£ç¡®")
            else:
                print("   âŒ é”™è¯¯")
        
        print("âœ… URLè¾¹ç•Œæƒ…å†µæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ URLè¾¹ç•Œæƒ…å†µæµ‹è¯•å¤±è´¥: {e}")
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)

def test_thread_safety():
    """æµ‹è¯•çº¿ç¨‹å®‰å…¨æ€§"""
    print("\nğŸ§ª æµ‹è¯•çº¿ç¨‹å®‰å…¨æ€§...")
    
    temp_dir = tempfile.mkdtemp(prefix="cloner_thread_test_")
    
    try:
        config = DownloadConfig(
            base_url="https://example.com",
            output_dir=temp_dir,
            max_depth=1,
            max_threads=5
        )
        
        cloner = WebsiteCloner(config)
        
        # æµ‹è¯•é˜Ÿåˆ—æ“ä½œ
        test_urls = [
            "https://example.com/page1.html",
            "https://example.com/page2.html",
            "https://example.com/page3.html",
        ]
        
        # æ·»åŠ URLåˆ°é˜Ÿåˆ—
        for url in test_urls:
            cloner.url_queue.put({'url': url, 'depth': 0, 'referrer': None})
        
        print(f"   é˜Ÿåˆ—å¤§å°: {cloner.url_queue.qsize()}")
        
        # æµ‹è¯•çº¿ç¨‹å®‰å…¨çš„é›†åˆæ“ä½œ
        with cloner._lock:
            cloner.downloaded_urls.add("https://example.com/test.html")
            cloner.failed_urls.add("https://example.com/failed.html")
        
        print(f"   å·²ä¸‹è½½URLæ•°é‡: {len(cloner.downloaded_urls)}")
        print(f"   å¤±è´¥URLæ•°é‡: {len(cloner.failed_urls)}")
        
        print("âœ… çº¿ç¨‹å®‰å…¨æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ çº¿ç¨‹å®‰å…¨æµ‹è¯•å¤±è´¥: {e}")
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)

def test_domain_filtering():
    """æµ‹è¯•åŸŸåè¿‡æ»¤åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•åŸŸåè¿‡æ»¤...")
    
    temp_dir = tempfile.mkdtemp(prefix="cloner_domain_test_")
    
    try:
        config = DownloadConfig(
            base_url="https://example.com",
            output_dir=temp_dir,
            max_depth=2
        )
        
        cloner = WebsiteCloner(config)
        
        # æµ‹è¯•å„ç§URL
        test_cases = [
            ("https://example.com/page.html", True),
            ("https://example.com/sub/page.html", True),
            ("https://other.com/page.html", False),
            ("https://sub.example.com/page.html", False),  # ä¸¥æ ¼åŒ¹é…
        ]
        
        for url, expected in test_cases:
            should_download = cloner._should_download_url(url, 0)
            result = "âœ…" if should_download == expected else "âŒ"
            print(f"   {result} {url} -> {should_download}")
        
        print("âœ… åŸŸåè¿‡æ»¤æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ åŸŸåè¿‡æ»¤æµ‹è¯•å¤±è´¥: {e}")
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)

def test_extension_filtering():
    """æµ‹è¯•æ–‡ä»¶æ‰©å±•åè¿‡æ»¤"""
    print("\nğŸ§ª æµ‹è¯•æ‰©å±•åè¿‡æ»¤...")
    
    temp_dir = tempfile.mkdtemp(prefix="cloner_ext_test_")
    
    try:
        config = DownloadConfig(
            base_url="https://example.com",
            output_dir=temp_dir,
            max_depth=2,
            allowed_extensions={'.html', '.css', '.js'},
            excluded_extensions={'.pdf'}
        )
        
        cloner = WebsiteCloner(config)
        
        test_cases = [
            ("https://example.com/page.html", True),
            ("https://example.com/style.css", True),
            ("https://example.com/script.js", True),
            ("https://example.com/image.png", False),
            ("https://example.com/document.pdf", False),
        ]
        
        for url, expected in test_cases:
            should_download = cloner._should_download_url(url, 0)
            result = "âœ…" if should_download == expected else "âŒ"
            print(f"   {result} {url} -> {should_download}")
        
        print("âœ… æ‰©å±•åè¿‡æ»¤æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ‰©å±•åè¿‡æ»¤æµ‹è¯•å¤±è´¥: {e}")
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)

def test_robots_txt_simulation():
    """æ¨¡æ‹Ÿrobots.txtæµ‹è¯•"""
    print("\nğŸ§ª æµ‹è¯•robots.txtå¤„ç†...")
    
    temp_dir = tempfile.mkdtemp(prefix="cloner_robots_test_")
    
    try:
        config = DownloadConfig(
            base_url="https://example.com",
            output_dir=temp_dir,
            follow_robots_txt=False  # ç®€åŒ–æµ‹è¯•
        )
        
        cloner = WebsiteCloner(config)
        
        # æµ‹è¯•robotsæ£€æŸ¥
        is_allowed = cloner._is_allowed_by_robots("https://example.com/allowed")
        print(f"   robots.txtæ£€æŸ¥: {is_allowed} (åº”è¯¥ä¸ºTrueï¼Œå› ä¸ºæ²¡æœ‰é…ç½®robots)")
        
        print("âœ… robots.txtæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ robots.txtæµ‹è¯•å¤±è´¥: {e}")
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)

def run_comprehensive_tests():
    """è¿è¡Œå…¨é¢çš„ä»£ç æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹å…¨é¢çš„ä»£ç åˆ†ææµ‹è¯•...")
    print("=" * 60)
    
    test_url_processing_edge_cases()
    test_thread_safety()
    test_domain_filtering()
    test_extension_filtering()
    test_robots_txt_simulation()
    
    print("\n" + "=" * 60)
    print("ğŸ å…¨é¢æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    run_comprehensive_tests()